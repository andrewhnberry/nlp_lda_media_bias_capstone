{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have done our Topic Modeling, we will need to do some sentitmental Analysis for each of the text. So we can determine if there are difference of sentiment that each outlet has for the topics we found in our LDA anlaysis. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plugins we need\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For our sentiment analysis\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sentiment_ready.csv')\n",
    "df = df.drop(labels = ['Unnamed: 0' ,'Perc_Contribution'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>507</td>\n",
       "      <td>507</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic_Keywords  Text  Source\n",
       "Topic                              \n",
       "1                 244   244     244\n",
       "2                 831   831     831\n",
       "3                   2     2       2\n",
       "4                 110   110     110\n",
       "5                 188   188     188\n",
       "6                  37    37      37\n",
       "7                  35    35      35\n",
       "8                  42    42      42\n",
       "9                  19    19      19\n",
       "10                180   180     180\n",
       "11                320   320     320\n",
       "12                507   507     507\n",
       "13                 27    27      27\n",
       "14                 19    19      19\n",
       "15                190   190     190\n",
       "16                319   319     319\n",
       "17                291   291     291\n",
       "18                 31    31      31\n",
       "19                434   434     434\n",
       "20                 46    46      46\n",
       "21                174   174     174\n",
       "22                 59    59      59"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Topic').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>china, chinese, military, iran, world, u.s., s...</td>\n",
       "      <td>Ebrahim Hamid, AFP | African Union's envoy to ...</td>\n",
       "      <td>France24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>u.s., mexico, trump, said, tariff, american, w...</td>\n",
       "      <td>Jorge Duenes, Reuters | ¬ Trucks wait in queue...</td>\n",
       "      <td>France24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>trump, president, said, official, n’t, would, ...</td>\n",
       "      <td>Luisa Gonzalez, REUTERS | A Colombian army mem...</td>\n",
       "      <td>France24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>queen, club, white, sherpa, virginia_beach, pe...</td>\n",
       "      <td>Real Madrid ended their long pursuit of Eden H...</td>\n",
       "      <td>France24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>said, health, study, research, food, fda, scie...</td>\n",
       "      <td>Ted Alijibe, AFP | Volunteers remove rubbish w...</td>\n",
       "      <td>France24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic                                     Topic_Keywords  \\\n",
       "0     10  china, chinese, military, iran, world, u.s., s...   \n",
       "1      1  u.s., mexico, trump, said, tariff, american, w...   \n",
       "2     12  trump, president, said, official, n’t, would, ...   \n",
       "3     20  queen, club, white, sherpa, virginia_beach, pe...   \n",
       "4     21  said, health, study, research, food, fda, scie...   \n",
       "\n",
       "                                                Text    Source  \n",
       "0  Ebrahim Hamid, AFP | African Union's envoy to ...  France24  \n",
       "1  Jorge Duenes, Reuters | ¬ Trucks wait in queue...  France24  \n",
       "2  Luisa Gonzalez, REUTERS | A Colombian army mem...  France24  \n",
       "3  Real Madrid ended their long pursuit of Eden H...  France24  \n",
       "4  Ted Alijibe, AFP | Volunteers remove rubbish w...  France24  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score_list = [round(TextBlob(article).sentiment.polarity, 3) for article in df['Text']]\n",
    "\n",
    "sentiment_subjectivity_list = [round(TextBlob(article).sentiment.subjectivity, 3) for article in df['Text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss = pd.DataFrame([list(df['Topic']), sentiment_score_list]).T\n",
    "df_ss.columns= ['Topic','Sentiment Score']\n",
    "#df_ss['Text'] = df['Text']\n",
    "df_ss['Source'] = df['Source']\n",
    "df_ss['Keywords'] = df['Topic_Keywords']\n",
    "len(df_ss)\n",
    "\n",
    "\n",
    "df_subjectivity = pd.DataFrame([list(df['Topic']), sentiment_subjectivity_list]).T\n",
    "df_subjectivity.columns = ['Topic', 'Subjectivity Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Source</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>France24</td>\n",
       "      <td>china, chinese, military, iran, world, u.s., s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.077</td>\n",
       "      <td>France24</td>\n",
       "      <td>u.s., mexico, trump, said, tariff, american, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.057</td>\n",
       "      <td>France24</td>\n",
       "      <td>trump, president, said, official, n’t, would, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.055</td>\n",
       "      <td>France24</td>\n",
       "      <td>queen, club, white, sherpa, virginia_beach, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.079</td>\n",
       "      <td>France24</td>\n",
       "      <td>said, health, study, research, food, fda, scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Sentiment Score    Source  \\\n",
       "0   10.0            0.009  France24   \n",
       "1    1.0            0.077  France24   \n",
       "2   12.0            0.057  France24   \n",
       "3   20.0            0.055  France24   \n",
       "4   21.0            0.079  France24   \n",
       "\n",
       "                                            Keywords  \n",
       "0  china, chinese, military, iran, world, u.s., s...  \n",
       "1  u.s., mexico, trump, said, tariff, american, w...  \n",
       "2  trump, president, said, official, n’t, would, ...  \n",
       "3  queen, club, white, sherpa, virginia_beach, pe...  \n",
       "4  said, health, study, research, food, fda, scie...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subjectivity.head()\n",
    "df_ss['Subjectivity Score'] = df_subjectivity['Subjectivity Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ss.to_csv('tableau_ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
